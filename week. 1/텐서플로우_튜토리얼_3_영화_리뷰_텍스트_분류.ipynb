{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "텐서플로우 튜토리얼 #3 - 영화 리뷰 텍스트 분류",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C70bwPH-iPMD"
      },
      "source": [
        "## 정확히 이해되지 않은 개념\n",
        "\n",
        "+ Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y80vr79-CHj_"
      },
      "source": [
        "# 영화 리뷰를 통한 텍스트 분류\n",
        "\n",
        "본 튜토리얼은 [텐서플로우 공식 튜토리얼](https://www.tensorflow.org/tutorials/keras/text_classification)을 참고하여 제가 이해한 내용을 바탕으로 작성되었습니다.\n",
        "\n",
        "이번 튜토리얼에서는 영화 리뷰(review) 텍스트를 긍정(positive) 또는 부정(negative)으로 분류해봅니다. 이번 예제는 **이진(binary) 또는 클래스(class)가 두 개인 분류 문제**입니다. **이진 분류는 머신러닝에서 중요하고 널리 사용됩니다.**\n",
        "\n",
        "[인터넷 영화 데이터베이스](https://www.imdb.com/)(Internet Movie Database)에서 수집한 50,000개의 영화 리뷰 텍스트를 담은 **IMDB 데이터셋**을 사용합니다. **25,000개의 리뷰는 훈련용**으로, **나머지 25,000개는 테스트용**으로 나뉘어져 있습니다. 훈련 세트와 테스트 세트의 클래스는 균형이 잡혀 있습니다. 즉, 긍정적인 리뷰와 부정적인 리뷰의 개수가 동일합니다.\n",
        "\n",
        "keras와 numpy를 임포트합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeiqvWrLBXGj"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9SnjoBRDZdN"
      },
      "source": [
        "## 1. IMDB 데이터셋 다운로드\n",
        "\n",
        "IMDB 데이터셋은 텐서플로와 함께 제공됩니다. **리뷰(단어의 시퀀스(sequence))**는 미리 전처리해서 **정수 시퀀스로 변환**되어 있습니다. **각 정수는 어휘 사전에 있는 특정 단어를 의미**합니다.\n",
        "\n",
        "다음 코드로 IMDB 데이터셋을 컴퓨터에 다운로드해봅시다.(이전에 다운로드를 받았다면 캐시된 복사본을 사용합니다)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjK9GQKEEBk7",
        "outputId": "b68f564e-1f99-40d5-c3f8-d7fad633eb11"
      },
      "source": [
        "imdb = keras.datasets.imdb\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX1HZAopEWFM"
      },
      "source": [
        "매개변수 `num_words=10000`은 훈련 데이터에서 가장 많이 등장하는 상위 10,000개의 단어를 선택합니다. **데이터 크기를 적당하게 유지하기 위해** 드물게 등장하는 단어는 제외합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsAqzUQvEzg5"
      },
      "source": [
        "## 2. 데이터 탐색\n",
        "\n",
        "데이터 형태를 알아보겠습니다. IMDB 데이터셋의 샘플은 전치리된 정수 배열입니다.  이 정수는 영화 리뷰에 나오는 단어를 나타냅니다. 레이블(label)은 정수 0 또는 1입니다.\n",
        "+ 0 : 부정적인 리뷰\n",
        "+ 1 : 긍정적인 리뷰"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hv0yj6PeFyPt",
        "outputId": "3758dda5-60b8-4da8-be21-243603a52c38"
      },
      "source": [
        "print(\"훈련 샘플: {}, 레이블: {}\".format(len(train_data), len(train_labels)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련 샘플: 25000, 레이블: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2qHEEM_F8ko"
      },
      "source": [
        "리뷰 텍스트는 어휘 사전의 특정 단어를 나타내는 정수로 변환되어 있습니다. \n",
        "\n",
        "첫 번째 리뷰를 확인해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUFmafxyGGP2",
        "outputId": "52e05f61-e2f8-400e-ba32-c419fa704439"
      },
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lb5oT1KFF8fT"
      },
      "source": [
        "영화 리뷰들은 길이가 다릅니다. 신경망의 입력은 길이가 같아야 하기 때문에 이 문제는 나중에 해결하겠습니다.\n",
        "\n",
        "다음 코드는 첫 번째 리뷰와 두 번째 리뷰에서 단어의 개수를 출력합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3u3k9UvRHOb0",
        "outputId": "7435a160-a7c7-4c84-d90f-aa4ab378c99e"
      },
      "source": [
        "len(train_data[0]), len(train_data[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(218, 189)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXTyTC_sHzlP"
      },
      "source": [
        "### 정수를 단어로 다시 변환하기\n",
        "\n",
        "정수를 다시 텍스트로 변환해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sseI9O6YIIuT",
        "outputId": "0bdd187d-75f9-4fe4-dd12-a7d2119a3d4f"
      },
      "source": [
        "# 단어와 정수 인덱스를 매핑한 딕셔너리를 다운로드한다.\n",
        "# {단어: 정수} 형태의 딕셔너리이다.\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# 기존에 매핑된 정수 값에 +3을 한다. 이 과정을 거치면 word_index[0, 1, 2, 3]이 비어있게 된다.\n",
        "word_index = {k:(v+3) for k, v in word_index.items()}\n",
        "# word_index[0, 1, 2, 3]을 채워준다.\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  # unknown\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "# key값과 value값의 위치를 바꿔놓은 reverse 딕셔너리를 하나 만들어준다.\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "# 정수 배열(reverse_word_index의 key)이 들어왔을 때 이에 대응되는 단어(reverse_word_index의 value)를 공백으로 결합해서 출력.\n",
        "# 대응되는 단어가 없는 정수가 들어왔을 때는 '?' 출력\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5gaT_5pJqIP"
      },
      "source": [
        "이제 `decode_review`함수를 사용해 첫 번째 리뷰 텍스트를 출력할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "P5tFHX3NIy8D",
        "outputId": "6397f454-81f8-4c5b-8637-d402db49cfc4"
      },
      "source": [
        "decode_review(train_data[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOrmxnCuS7CK"
      },
      "source": [
        "(PAD는 아래의 패딩 과정을 수행하면서 부족한 길이만큼 0으로 매꿔주었기 때문에 발생했다)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxlai7exLCIA"
      },
      "source": [
        "## 3. 데이터 준비\n",
        "\n",
        "리뷰(정수 배열)는 신경망에 주입하기 전에 텐서로 변환되어야 합니다. 변환하는 방법에는 몇 가지가 있습니다.\n",
        "\n",
        "+ 원-핫 인코딩(one-hot encoding) : 정수 배열을 0과 1로 이루어진 벡터로 변환합니다. 예를 들어 배열[3, 5]을 인덱스 3과 5만 1이고 나머지는 모두 0인 10,000차원 벡터로 변환할 수 있습니다. 이후 실수 벡터 데이터를 다룰 수 있는 layer(dense)를 신경망의 첫 번째 layer로 사용합니다. 이 방법은 `num_words * num_reviews` 크기의 행렬이 필요하기 때문에 **메모리를 많이 사용**합니다.\n",
        "+ 패딩(padding) : **정수 배열의 길이가 모두 같도록 패딩(padding)을 추가**해 `max_length * num_reviews` 크기의 정수 텐서를 만듭니다. 이런 형태의 텐서를 다룰 수 있는 임베딩(embedding) layer를 신경망의 첫 번째 layer로 사용할 수 있습니다.\n",
        "\n",
        "이번 튜토리얼에서는 **두 번째 방식**을 사용합니다.\n",
        "\n",
        "영화 리뷰의 길이가 같아야 하므로 [pad_sequences](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences) 함수를 사용해 길이를 맞추겠습니다.\n",
        "\n",
        "+ pad_sequences : 2차원의 정수 배열을 2차원의 넘파이 배열로 변환한다. `maxlen`를 설정하면 각 행이 그보다 짧은 길이인 경우 부족한 길이만큼 앞(padding='pre') 또는 뒤(padding='post')를 특정 값(value=n)으로 채운다. `maxlen`을 초과한 길이일 경우 앞(truncating='pre') 또는 뒤(truncating='post')를 자른다.\n",
        "+ pad_sequences(sequence, value, padding, maxlen)\n",
        "\n",
        "(디폴트 값 - value : 0, padding='pre', dtype=int32, truncating='pre', maxlen=가장 긴 행의 길이)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcwOKUekMQks"
      },
      "source": [
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data, \n",
        "                                                        padding='post', \n",
        "                                                        maxlen=256)\n",
        "\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
        "                                                       value=word_index[\"<PAD>\"],\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=256)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5xHBuO2M0aa"
      },
      "source": [
        "이전에는 훈련 세트의 첫 번째와 두 번째의 데이터의 길이가 달랐습니다. 위의 처리 과정을 거친 후에 샘플의 길이를 다시 확인해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10LW8elnMYG6",
        "outputId": "1ab2a096-8ef6-4c63-836c-a47f9773d445"
      },
      "source": [
        "len(train_data[0]), len(train_data[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXhpcfl1NT9O"
      },
      "source": [
        "길이가 같아졌음을 확인할 수 있습니다.\n",
        "\n",
        "첫 번째 리뷰 내용을 확인해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1IfVaifNapI",
        "outputId": "050bb507-a1b6-4c22-e5e3-e48b80fc5a70"
      },
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   1   14   22   16   43  530  973 1622 1385   65  458 4468   66 3941\n",
            "    4  173   36  256    5   25  100   43  838  112   50  670    2    9\n",
            "   35  480  284    5  150    4  172  112  167    2  336  385   39    4\n",
            "  172 4536 1111   17  546   38   13  447    4  192   50   16    6  147\n",
            " 2025   19   14   22    4 1920 4613  469    4   22   71   87   12   16\n",
            "   43  530   38   76   15   13 1247    4   22   17  515   17   12   16\n",
            "  626   18    2    5   62  386   12    8  316    8  106    5    4 2223\n",
            " 5244   16  480   66 3785   33    4  130   12   16   38  619    5   25\n",
            "  124   51   36  135   48   25 1415   33    6   22   12  215   28   77\n",
            "   52    5   14  407   16   82    2    8    4  107  117 5952   15  256\n",
            "    4    2    7 3766    5  723   36   71   43  530  476   26  400  317\n",
            "   46    7    4    2 1029   13  104   88    4  381   15  297   98   32\n",
            " 2071   56   26  141    6  194 7486   18    4  226   22   21  134  476\n",
            "   26  480    5  144   30 5535   18   51   36   28  224   92   25  104\n",
            "    4  226   65   16   38 1334   88   12   16  283    5   16 4472  113\n",
            "  103   32   15   16 5345   19  178   32    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBy4p3CjNp6o"
      },
      "source": [
        "## 4. 모델 구성\n",
        "\n",
        "신경망에 layer를 쌓을 때 두 가지를 결정해야 합니다.\n",
        "\n",
        "+ 모델에서 얼마나 많은 층을 사용할 것인가?\n",
        "+ 각 층에서 얼마나 많은 hidden unit을 사용할 것인가?\n",
        "\n",
        "이 예제의 입력 데이터는 단어 인덱스의 배열입니다. 예측할 레이블은 0 또는 1입니다. 이 문제에 맞는 모델을 구성해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27vqa1bYTegz",
        "outputId": "55540ce0-bba9-4a86-b2ff-f4b1e0ce195d"
      },
      "source": [
        "vocab_size = 10000\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size, 16, input_shape=(None,)))\n",
        "model.add(keras.layers.GlobalAveragePooling1D())\n",
        "model.add(keras.layers.Dense(16, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,289\n",
            "Trainable params: 160,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9bVK4BnVFOI"
      },
      "source": [
        "층을 순서대로 쌓아 분류기(classifier)를 만듭니다.\n",
        "\n",
        "\n",
        "\n",
        "1.   첫 번째 층은 `Embedding` 층입니다. 이 층은 정수로 인코딩된 단어를 입력 받고 각 단어 인덱스에 해당하는 임베딩 벡터를 찾습니다. 이 벡터는 모델이 훈련되면서 학습됩니다. 이 벡터는 출력 배열에 새로운 차원으로 추가됩니다. 최종 차원은 (batch, sequence, embedding)이 됩니다.\n",
        "+ [언어의 벡터화(Word Embedding)](https://simpling.tistory.com/1)\n",
        "+ vocab_size : data의 총단어 개수\n",
        "+ 16 : 차원이 16인 벡터를 만든다는 뜻. 즉, 행의 길이가 16인 벡터를 만든다.\n",
        "+ 특정 단어에 대해 랜덤하게 16개의 실수형 가중치를 생성한다.\n",
        "2.   두 번째 층은 `GlobalAveragePooling1D` 층입니다. 이 층은 `sequence` 차원에 대해 평균을 계산하여 각 샘플에 대해 고정된 길이의 출력 벡터를 반환합니다. 길이가 다른 입력을 다루는 가장 간단한 방법입니다.\n",
        "+ 앞서 임베딩 레이어에서 각 열의 평균을 구한 크기 16의 벡터를 리턴한다.\n",
        "+ 2차원의 데이터를 1차원으로 리턴하는 효과.\n",
        "3.   세 번째 층은 16개의 hidden unit을 가진 완전 연결(fully-connected)층입니다.\n",
        "4.   마지막 층은 하나의 출력 노드를 가진 완전 연결 층입니다. `sigmoid` 활성화 함수를 사용하여 0~1 사이의 실수를 출력합니다. 이 값은 확률 또는 신뢰도를 나타냅니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WaRBInBZBoS"
      },
      "source": [
        "### Hidden Unit\n",
        "\n",
        "위 모델에는 입력(첫 번째 층)과 출력(마지막 층) 사이에 두 개의 중간 또는 '은닉'층이 있습니다.\n",
        "\n",
        "모델에 많은 은닉 유닛(고차원의 표현 공간)과 층이 있다면 신경망은 더 복잡한 표현을 학습할 수 있습니다. 하지만 신경망의 계산 비용이 많이 들고 원치않는 패턴을 학습할 수도 있습니다. 이런 표현은** 훈련 데이터의 성능을 향상시키지만 테스트 데이터에서는 그렇지 못합니다.** 이를 **과대적합(overfitting)**이라고 부릅니다. 후에 이에 대해 알아보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tNkI316bBYY"
      },
      "source": [
        "### 모델 컴파일\n",
        "\n",
        "모델이 훈련하려면 손실 함수(loss function)과 옵티마이저(optimizer)가 필요합니다. 이번 예제는 **이진 분류 문제이고 모델이 확률을 출력하므로(출력층의 유닛이 하나이고 sigmoid 활성화 함수를 사용하므로)**, `binary_crossentropy` 손실 함수를 사용하겠습니다.\n",
        "\n",
        "다른 손실 함수를 선택할 수 없는 것은 아닙니다. 예를 들어 `mean_squared_error`를 선택할 수 있습니다. 하지만 일반적으로 `binary_crossentropy`가 확률을 다루는데 적합합니다. 이 함수는 확률 분포 간의 거리를 측정합니다. 여기에서는 정답인 타깃 분포와 예측 분포 사이의 거리입니다.\n",
        "\n",
        "나중에 회귀(regression)문제에 대해 살펴 볼 때 평균 제곱 오차(mean_squared error) 손실 함수를 어떻게 사용하는지 알아 보겠습니다.\n",
        "\n",
        "옵티마이저로는 Adam 알고리즘을 구현한 AdamOptimizer를 사용합니다. 경사하강법을 사용하는 GradientDescentOptimizer보다 성능이 좋다고 합니다.\n",
        "\n",
        "이제 모델이 사용할 옵티마이저와 손실 함수를 설정해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPlJCXH1brcd"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoQdjkJ3cdoR"
      },
      "source": [
        "## 5. 검증 세트 만들기\n",
        "\n",
        "모델을 훈련할 때 모델이 만난 적 없는 데이터에서 정확도를 확인하는 것이 좋습니다. 원본 훈련 데이터에서 10,000개의 샘플을 떼어내어 검증 세트를 만들겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd2qcHHEwl4G"
      },
      "source": [
        "x_val = train_data[:10000]  # 0~9999, 검증 데이터(10,000개)\n",
        "partial_x_train = train_data[10000:] # 10000~24999, 훈련 데이터(15,000개)\n",
        "\n",
        "y_val = train_labels[:10000]  # 0~9999, 검증 데이터\n",
        "partial_y_train = train_labels[10000:]  # 10000~24999, 훈련 데이터"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AteAilqmw6nP"
      },
      "source": [
        "## 6. 모델 훈련\n",
        "\n",
        "훈련 데이터셋(partial_x_train, partial_y_train)을 512개의 작은 미니배치(mini-batches)로 분할해 입력으로 사용합니다.\n",
        "\n",
        "512개씩 나누어 전체 훈련 데이터셋을 모델 학습에 사용하는 것을 40번 반복합니다.\n",
        "\n",
        "모델이 학습되는 동안 모델의 손실과 정확도를 계산하기 위해 검증 데이터셋(x_val, y_val)을 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KN69q4iKxfTC",
        "outputId": "c5d960fb-ee07-4d4b-b8bf-9204a4e73248"
      },
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "30/30 [==============================] - 4s 20ms/step - loss: 0.6922 - accuracy: 0.5881 - val_loss: 0.6909 - val_accuracy: 0.6423\n",
            "Epoch 2/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.6883 - accuracy: 0.6553 - val_loss: 0.6854 - val_accuracy: 0.7279\n",
            "Epoch 3/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.6795 - accuracy: 0.7462 - val_loss: 0.6738 - val_accuracy: 0.7365\n",
            "Epoch 4/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.6625 - accuracy: 0.7604 - val_loss: 0.6538 - val_accuracy: 0.7538\n",
            "Epoch 5/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.6357 - accuracy: 0.7789 - val_loss: 0.6248 - val_accuracy: 0.7674\n",
            "Epoch 6/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.5999 - accuracy: 0.7937 - val_loss: 0.5888 - val_accuracy: 0.7883\n",
            "Epoch 7/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.5579 - accuracy: 0.8142 - val_loss: 0.5491 - val_accuracy: 0.8009\n",
            "Epoch 8/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.5146 - accuracy: 0.8277 - val_loss: 0.5101 - val_accuracy: 0.8140\n",
            "Epoch 9/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4715 - accuracy: 0.8441 - val_loss: 0.4732 - val_accuracy: 0.8314\n",
            "Epoch 10/40\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4319 - accuracy: 0.8587 - val_loss: 0.4403 - val_accuracy: 0.8413\n",
            "Epoch 11/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3969 - accuracy: 0.8684 - val_loss: 0.4124 - val_accuracy: 0.8487\n",
            "Epoch 12/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3666 - accuracy: 0.8792 - val_loss: 0.3885 - val_accuracy: 0.8545\n",
            "Epoch 13/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3397 - accuracy: 0.8859 - val_loss: 0.3687 - val_accuracy: 0.8615\n",
            "Epoch 14/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3171 - accuracy: 0.8935 - val_loss: 0.3533 - val_accuracy: 0.8637\n",
            "Epoch 15/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2979 - accuracy: 0.8989 - val_loss: 0.3400 - val_accuracy: 0.8705\n",
            "Epoch 16/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2809 - accuracy: 0.9028 - val_loss: 0.3304 - val_accuracy: 0.8688\n",
            "Epoch 17/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2659 - accuracy: 0.9069 - val_loss: 0.3212 - val_accuracy: 0.8743\n",
            "Epoch 18/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2523 - accuracy: 0.9122 - val_loss: 0.3147 - val_accuracy: 0.8761\n",
            "Epoch 19/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2402 - accuracy: 0.9169 - val_loss: 0.3080 - val_accuracy: 0.8793\n",
            "Epoch 20/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2286 - accuracy: 0.9207 - val_loss: 0.3026 - val_accuracy: 0.8792\n",
            "Epoch 21/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2187 - accuracy: 0.9242 - val_loss: 0.2992 - val_accuracy: 0.8809\n",
            "Epoch 22/40\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.2091 - accuracy: 0.9265 - val_loss: 0.2950 - val_accuracy: 0.8817\n",
            "Epoch 23/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2000 - accuracy: 0.9308 - val_loss: 0.2923 - val_accuracy: 0.8828\n",
            "Epoch 24/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1918 - accuracy: 0.9349 - val_loss: 0.2901 - val_accuracy: 0.8840\n",
            "Epoch 25/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1839 - accuracy: 0.9381 - val_loss: 0.2892 - val_accuracy: 0.8838\n",
            "Epoch 26/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1766 - accuracy: 0.9421 - val_loss: 0.2884 - val_accuracy: 0.8841\n",
            "Epoch 27/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1699 - accuracy: 0.9453 - val_loss: 0.2899 - val_accuracy: 0.8815\n",
            "Epoch 28/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1640 - accuracy: 0.9475 - val_loss: 0.2865 - val_accuracy: 0.8852\n",
            "Epoch 29/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1568 - accuracy: 0.9502 - val_loss: 0.2862 - val_accuracy: 0.8858\n",
            "Epoch 30/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1509 - accuracy: 0.9533 - val_loss: 0.2868 - val_accuracy: 0.8857\n",
            "Epoch 31/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1457 - accuracy: 0.9551 - val_loss: 0.2874 - val_accuracy: 0.8855\n",
            "Epoch 32/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1402 - accuracy: 0.9571 - val_loss: 0.2893 - val_accuracy: 0.8837\n",
            "Epoch 33/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1346 - accuracy: 0.9599 - val_loss: 0.2892 - val_accuracy: 0.8854\n",
            "Epoch 34/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1303 - accuracy: 0.9617 - val_loss: 0.2909 - val_accuracy: 0.8850\n",
            "Epoch 35/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1250 - accuracy: 0.9637 - val_loss: 0.2922 - val_accuracy: 0.8857\n",
            "Epoch 36/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1203 - accuracy: 0.9653 - val_loss: 0.2941 - val_accuracy: 0.8861\n",
            "Epoch 37/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1162 - accuracy: 0.9673 - val_loss: 0.2959 - val_accuracy: 0.8851\n",
            "Epoch 38/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1119 - accuracy: 0.9687 - val_loss: 0.2981 - val_accuracy: 0.8849\n",
            "Epoch 39/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1080 - accuracy: 0.9693 - val_loss: 0.3012 - val_accuracy: 0.8854\n",
            "Epoch 40/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1046 - accuracy: 0.9710 - val_loss: 0.3031 - val_accuracy: 0.8834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwRHgoHsyHmD"
      },
      "source": [
        "## 7. 모델 평가\n",
        "\n",
        "모델의 성능을 확인해봅시다. 손실과 정확도를 반환합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIvJLJq9yOme",
        "outputId": "2e3a7e30-69ef-4f55-ec6c-1b80ba58f0ae"
      },
      "source": [
        "results = model.evaluate(test_data, test_labels, verbose=2)\n",
        "\n",
        "print(results)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 - 1s - loss: 0.3221 - accuracy: 0.8733\n",
            "[0.3220793604850769, 0.8733199834823608]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqZfGKNxyWeV"
      },
      "source": [
        "이번 예제는 매우 단순한 방식을 사용하므로 **87%의 정확도**를 달성했습니다. 좀 더 심층적인 방법을 사용하면 모델은 95%에 가까운 정확도를 얻습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qbAiU_byf6H"
      },
      "source": [
        "## 8. 정확도와 손실 그래프 그리기\n",
        "\n",
        "`model.fit()`은 `History` 객체를 반환합니다. `History`에는 훈련하는 동안 일어난 모든 정보가 담긴 딕셔너리가 들어있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UDZn6kay5jB",
        "outputId": "6f043fca-5cbf-4571-8df2-8d2872c412d4"
      },
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PokFUK5LzCvo"
      },
      "source": [
        "네 개의 항목이 있습니다. 훈련과 검증 단계에서 모니터링하는 지표들입니다.\n",
        "\n",
        "훈련 손실과 검증 손실을 그래프로 그려 보고, 훈련 정확도와 검증 정확도 역시 그래프로 그려서 비교해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "mtU-vvnHzLR9",
        "outputId": "d7895e25-1b57-441f-ba77-07cf1bd79370"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# 'bo'는 파란색 점입니다.\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# 'b'는 파란 실선입니다.\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()  # 범례를 나타낸다.\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "ATE1cSjR0HII",
        "outputId": "b4545229-16a3-4307-d212-6a3466875a15"
      },
      "source": [
        "plt.clf()  # 그림 초기화\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()  # 범례를 나타낸다.\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSGyREjb0k9D"
      },
      "source": [
        "훈련 손실은 에포크마다 감소하고, 훈련 정확도는 증가합니다. 경사 하강법 최적화를 사용할 때 볼 수 있는 현상입니다. 매 반복마다 최적화 대상의 값을 최소화합니다.\n",
        "\n",
        "하지만 검증 손실과 검증 정확도에서는 약 20번째 에포크 이후에는 변화가 없습니다. 이렇듯 훈련 데이터셋을 입력으로 사용했을 때보다 검증 데이터셋을 입력으로 사용했을 때 결과가 좋지 못한 것을 오버피팅(overfitting)이라고 합니다.\n",
        "\n",
        "훈련용 데이터셋에 최적화되어 있어서 새로운 데이터셋을 입력으로 사용시 모델의 성능이 떨어지는 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myqQW6cX2TjH"
      },
      "source": [
        "## 9. 예측하기\n",
        "\n",
        "학습된 모델에 테스트 데이터셋을 입력으로 사용하여 예측해봅시다.\n",
        "\n",
        "예측된 값 중 10개만 출력해보았습니다. 첫 번째 줄은 신경망의 출력이고, 두 번째 줄은 어느 클래스에 속하는지 판정한 결과입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXNTddVJ2Ye5",
        "outputId": "53333c17-4465-431c-9e83-e117f8a81f9b"
      },
      "source": [
        "predictions = model.predict(test_data)\n",
        "print(predictions[0:10].T)\n",
        "\n",
        "predict_class=model.predict_classes(test_data)\n",
        "print(predict_class[0:10].T)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0860334  0.9991033  0.72272635 0.66176194 0.9946713  0.90922195\n",
            "  0.9499976  0.02515864 0.96619487 0.9991184 ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[0 1 1 1 1 1 1 0 1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}