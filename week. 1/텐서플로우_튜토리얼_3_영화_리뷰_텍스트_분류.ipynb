{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "텐서플로우 튜토리얼 #3 - 영화 리뷰 텍스트 분류",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C70bwPH-iPMD"
      },
      "source": [
        "## 정확히 이해되지 않은 개념\n",
        "\n",
        "+ Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y80vr79-CHj_"
      },
      "source": [
        "# 영화 리뷰를 통한 텍스트 분류\n",
        "\n",
        "본 튜토리얼은 [텐서플로우 공식 튜토리얼](https://www.tensorflow.org/tutorials/keras/text_classification)을 참고하여 제가 이해한 내용을 바탕으로 작성되었습니다.\n",
        "\n",
        "이번 튜토리얼에서는 영화 리뷰(review) 텍스트를 긍정(positive) 또는 부정(negative)으로 분류해봅니다. 이번 예제는 **이진(binary) 또는 클래스(class)가 두 개인 분류 문제**입니다. **이진 분류는 머신러닝에서 중요하고 널리 사용됩니다.**\n",
        "\n",
        "[인터넷 영화 데이터베이스](https://www.imdb.com/)(Internet Movie Database)에서 수집한 50,000개의 영화 리뷰 텍스트를 담은 **IMDB 데이터셋**을 사용합니다. **25,000개의 리뷰는 훈련용**으로, **나머지 25,000개는 테스트용**으로 나뉘어져 있습니다. 훈련 세트와 테스트 세트의 클래스는 균형이 잡혀 있습니다. 즉, 긍정적인 리뷰와 부정적인 리뷰의 개수가 동일합니다.\n",
        "\n",
        "keras와 numpy를 임포트합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeiqvWrLBXGj"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9SnjoBRDZdN"
      },
      "source": [
        "## 1. IMDB 데이터셋 다운로드\n",
        "\n",
        "IMDB 데이터셋은 텐서플로와 함께 제공됩니다. **리뷰(단어의 시퀀스(sequence))**는 미리 전처리해서 **정수 시퀀스로 변환**되어 있습니다. **각 정수는 어휘 사전에 있는 특정 단어를 의미**합니다.\n",
        "\n",
        "다음 코드로 IMDB 데이터셋을 컴퓨터에 다운로드해봅시다.(이전에 다운로드를 받았다면 캐시된 복사본을 사용합니다)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjK9GQKEEBk7",
        "outputId": "20991b36-dfc6-44f0-afed-ffd8b72765b7"
      },
      "source": [
        "imdb = keras.datasets.imdb\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX1HZAopEWFM"
      },
      "source": [
        "매개변수 `num_words=10000`은 훈련 데이터에서 가장 많이 등장하는 상위 10,000개의 단어를 선택합니다. **데이터 크기를 적당하게 유지하기 위해** 드물게 등장하는 단어는 제외합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsAqzUQvEzg5"
      },
      "source": [
        "## 2. 데이터 탐색\n",
        "\n",
        "데이터 형태를 알아보겠습니다. IMDB 데이터셋의 샘플은 전치리된 정수 배열입니다.  이 정수는 영화 리뷰에 나오는 단어를 나타냅니다. 레이블(label)은 정수 0 또는 1입니다.\n",
        "+ 0 : 부정적인 리뷰\n",
        "+ 1 : 긍정적인 리뷰"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hv0yj6PeFyPt",
        "outputId": "fce83efe-a713-434b-906b-7e270e64414b"
      },
      "source": [
        "print(\"훈련 샘플: {}, 레이블: {}\".format(len(train_data), len(train_labels)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련 샘플: 25000, 레이블: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2qHEEM_F8ko"
      },
      "source": [
        "리뷰 텍스트는 어휘 사전의 특정 단어를 나타내는 정수로 변환되어 있습니다. \n",
        "\n",
        "첫 번째 리뷰를 확인해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUFmafxyGGP2",
        "outputId": "f54c7280-f9b0-40eb-b48b-8dd1a4c64da5"
      },
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lb5oT1KFF8fT"
      },
      "source": [
        "영화 리뷰들은 길이가 다릅니다. 신경망의 입력은 길이가 같아야 하기 때문에 이 문제는 나중에 해결하겠습니다.\n",
        "\n",
        "다음 코드는 첫 번째 리뷰와 두 번째 리뷰에서 단어의 개수를 출력합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3u3k9UvRHOb0",
        "outputId": "a33134b6-2812-4ad5-ae0c-cddc34d0d978"
      },
      "source": [
        "len(train_data[0]), len(train_data[1])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(218, 189)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXTyTC_sHzlP"
      },
      "source": [
        "### 정수를 단어로 다시 변환하기\n",
        "\n",
        "정수를 다시 텍스트로 변환해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sseI9O6YIIuT",
        "outputId": "f0777deb-ea00-4561-d295-5868e0f498d2"
      },
      "source": [
        "# 단어와 정수 인덱스를 매핑한 딕셔너리를 다운로드한다.\n",
        "# {단어: 정수} 형태의 딕셔너리이다.\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# 기존에 매핑된 정수 값에 +3을 한다. 이 과정을 거치면 word_index[0, 1, 2, 3]이 비어있게 된다.\n",
        "word_index = {k:(v+3) for k, v in word_index.items()}\n",
        "# word_index[0, 1, 2, 3]을 채워준다.\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  # unknown\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "# key값과 value값의 위치를 바꿔놓은 reverse 딕셔너리를 하나 만들어준다.\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "# 정수 배열(reverse_word_index의 key)이 들어왔을 때 이에 대응되는 단어(reverse_word_index의 value)를 공백으로 결합해서 출력.\n",
        "# 대응되는 단어가 없는 정수가 들어왔을 때는 '?' 출력\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5gaT_5pJqIP"
      },
      "source": [
        "이제 `decode_review`함수를 사용해 첫 번째 리뷰 텍스트를 출력할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "P5tFHX3NIy8D",
        "outputId": "4a18927e-9465-4fde-aec2-ec12c1d088c6"
      },
      "source": [
        "decode_review(train_data[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOrmxnCuS7CK"
      },
      "source": [
        "(PAD는 아래의 패딩 과정을 수행하면서 부족한 길이만큼 0으로 매꿔주었기 때문에 발생했다)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxlai7exLCIA"
      },
      "source": [
        "## 3. 데이터 준비\n",
        "\n",
        "리뷰(정수 배열)는 신경망에 주입하기 전에 텐서로 변환되어야 합니다. 변환하는 방법에는 몇 가지가 있습니다.\n",
        "\n",
        "+ 원-핫 인코딩(one-hot encoding) : 정수 배열을 0과 1로 이루어진 벡터로 변환합니다. 예를 들어 배열[3, 5]을 인덱스 3과 5만 1이고 나머지는 모두 0인 10,000차원 벡터로 변환할 수 있습니다. 이후 실수 벡터 데이터를 다룰 수 있는 layer(dense)를 신경망의 첫 번째 layer로 사용합니다. 이 방법은 `num_words * num_reviews` 크기의 행렬이 필요하기 때문에 **메모리를 많이 사용**합니다.\n",
        "+ 패딩(padding) : **정수 배열의 길이가 모두 같도록 패딩(padding)을 추가**해 `max_length * num_reviews` 크기의 정수 텐서를 만듭니다. 이런 형태의 텐서를 다룰 수 있는 임베딩(embedding) layer를 신경망의 첫 번째 layer로 사용할 수 있습니다.\n",
        "\n",
        "이번 튜토리얼에서는 **두 번째 방식**을 사용합니다.\n",
        "\n",
        "영화 리뷰의 길이가 같아야 하므로 [pad_sequences](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences) 함수를 사용해 길이를 맞추겠습니다.\n",
        "\n",
        "+ pad_sequences : 2차원의 정수 배열을 2차원의 넘파이 배열로 변환한다. `maxlen`를 설정하면 각 행이 그보다 짧은 길이인 경우 부족한 길이만큼 앞(padding='pre') 또는 뒤(padding='post')를 특정 값(value=n)으로 채운다. `maxlen`을 초과한 길이일 경우 앞(truncating='pre') 또는 뒤(truncating='post')를 자른다.\n",
        "+ pad_sequences(sequence, value, padding, maxlen)\n",
        "\n",
        "(디폴트 값 - value : 0, padding='pre', dtype=int32, truncating='pre', maxlen=가장 긴 행의 길이)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcwOKUekMQks"
      },
      "source": [
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data, \n",
        "                                                        padding='post', \n",
        "                                                        maxlen=256)\n",
        "\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
        "                                                       value=word_index[\"<PAD>\"],\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=256)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5xHBuO2M0aa"
      },
      "source": [
        "이전에는 훈련 세트의 첫 번째와 두 번째의 데이터의 길이가 달랐습니다. 위의 처리 과정을 거친 후에 샘플의 길이를 다시 확인해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10LW8elnMYG6",
        "outputId": "fb6e2587-6798-4739-eb47-750f8d0c4e5a"
      },
      "source": [
        "len(train_data[0]), len(train_data[1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXhpcfl1NT9O"
      },
      "source": [
        "길이가 같아졌음을 확인할 수 있습니다.\n",
        "\n",
        "첫 번째 리뷰 내용을 확인해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1IfVaifNapI",
        "outputId": "4d4d4a8f-829b-445e-98bd-f14ba30126d5"
      },
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   1   14   22   16   43  530  973 1622 1385   65  458 4468   66 3941\n",
            "    4  173   36  256    5   25  100   43  838  112   50  670    2    9\n",
            "   35  480  284    5  150    4  172  112  167    2  336  385   39    4\n",
            "  172 4536 1111   17  546   38   13  447    4  192   50   16    6  147\n",
            " 2025   19   14   22    4 1920 4613  469    4   22   71   87   12   16\n",
            "   43  530   38   76   15   13 1247    4   22   17  515   17   12   16\n",
            "  626   18    2    5   62  386   12    8  316    8  106    5    4 2223\n",
            " 5244   16  480   66 3785   33    4  130   12   16   38  619    5   25\n",
            "  124   51   36  135   48   25 1415   33    6   22   12  215   28   77\n",
            "   52    5   14  407   16   82    2    8    4  107  117 5952   15  256\n",
            "    4    2    7 3766    5  723   36   71   43  530  476   26  400  317\n",
            "   46    7    4    2 1029   13  104   88    4  381   15  297   98   32\n",
            " 2071   56   26  141    6  194 7486   18    4  226   22   21  134  476\n",
            "   26  480    5  144   30 5535   18   51   36   28  224   92   25  104\n",
            "    4  226   65   16   38 1334   88   12   16  283    5   16 4472  113\n",
            "  103   32   15   16 5345   19  178   32    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBy4p3CjNp6o"
      },
      "source": [
        "## 4. 모델 구성\n",
        "\n",
        "신경망에 layer를 쌓을 때 두 가지를 결정해야 합니다.\n",
        "\n",
        "+ 모델에서 얼마나 많은 층을 사용할 것인가?\n",
        "+ 각 층에서 얼마나 많은 hidden unit을 사용할 것인가?\n",
        "\n",
        "이 예제의 입력 데이터는 단어 인덱스의 배열입니다. 예측할 레이블은 0 또는 1입니다. 이 문제에 맞는 모델을 구성해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27vqa1bYTegz",
        "outputId": "1437a60f-5cb7-4881-b240-239eb563f929"
      },
      "source": [
        "vocab_size = 10000\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size, 16, input_shape=(None,)))\n",
        "model.add(keras.layers.GlobalAveragePooling1D())\n",
        "model.add(keras.layers.Dense(16, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,289\n",
            "Trainable params: 160,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9bVK4BnVFOI"
      },
      "source": [
        "층을 순서대로 쌓아 분류기(classifier)를 만듭니다.\n",
        "\n",
        "\n",
        "\n",
        "1.   첫 번째 층은 `Embedding` 층입니다. 이 층은 정수로 인코딩된 단어를 입력 받고 각 단어 인덱스에 해당하는 임베딩 벡터를 찾습니다. 이 벡터는 모델이 훈련되면서 학습됩니다. 이 벡터는 출력 배열에 새로운 차원으로 추가됩니다. 최종 차원은 (batch, sequence, embedding)이 됩니다.\n",
        "+ [언어의 벡터화(Word Embedding)](https://simpling.tistory.com/1)\n",
        "+ vocab_size : data의 총단어 개수\n",
        "+ 16 : 차원이 16인 벡터를 만든다는 뜻. 즉, 행의 길이가 16인 벡터를 만든다.\n",
        "+ 특정 단어에 대해 랜덤하게 16개의 실수형 가중치를 생성한다.\n",
        "+ 하나의 리뷰에 차원이 16인 벡터가 256개 생성된다.(2차원 배열)\n",
        "2.   두 번째 층은 `GlobalAveragePooling1D` 층입니다. 이 층은 `sequence` 차원에 대해 평균을 계산하여 각 샘플에 대해 고정된 길이의 출력 벡터를 반환합니다. 길이가 다른 입력을 다루는 가장 간단한 방법입니다.\n",
        "+ 앞서 임베딩 레이어에서 각 열의 평균을 구한 크기 16의 벡터를 리턴한다.\n",
        "+ 2차원의 데이터를 1차원으로 리턴하는 효과.\n",
        "3.   세 번째 층은 16개의 hidden unit을 가진 완전 연결(fully-connected)층입니다.\n",
        "4.   마지막 층은 하나의 출력 노드를 가진 완전 연결 층입니다. `sigmoid` 활성화 함수를 사용하여 0~1 사이의 실수를 출력합니다. 이 값은 확률 또는 신뢰도를 나타냅니다. \n",
        "\n",
        "0에 가까우면 0, 1에 가까우면 1의 클래스로 분류됩니다. 이를 테스트 레이블과 비교해서 정확도를 측정합니다.\n",
        "\n",
        "즉, 하나의 리뷰 속 단어들을 랜덤으로 가중치를 둬서 하나의 확률로 리턴한 다음 이 리뷰가 원래 부정적(0)이었나 긍정적(1)이었나를 test_labels를 보고 버릴 것인지 취할 것인지 판단 후 최적화하면서 학습합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WaRBInBZBoS"
      },
      "source": [
        "### Hidden Unit\n",
        "\n",
        "위 모델에는 입력(첫 번째 층)과 출력(마지막 층) 사이에 두 개의 숨겨진 층이 있습니다.\n",
        "\n",
        "모델에 많은 Hidden Unit(고차원의 표현 공간)과 층이 있다면 신경망은 더 복잡한 표현을 학습할 수 있습니다. 하지만 신경망의 계산 비용이 많이 들고 원치않는 패턴을 학습할 수도 있습니다. 이런 표현은 **훈련 데이터의 성능을 향상시키지만 테스트 데이터에서는 어느 정도선까지만 성능이 향상됩니다.** 이를 **과대적합(overfitting)**이라고 부릅니다. 후에 이에 대해 알아보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tNkI316bBYY"
      },
      "source": [
        "### 모델 컴파일\n",
        "\n",
        "모델이 훈련하려면 손실 함수(loss function)과 옵티마이저(optimizer)가 필요합니다. 이번 예제는 **이진 분류 문제이고 모델이 확률을 출력하므로(출력층의 유닛이 하나이고 sigmoid 활성화 함수를 사용하므로)**, `binary_crossentropy` 손실 함수를 사용하겠습니다.\n",
        "\n",
        "다른 손실 함수를 선택할 수 없는 것은 아닙니다. 예를 들어 `mean_squared_error`를 선택할 수 있습니다. 하지만 일반적으로 `binary_crossentropy`가 확률을 다루는데 적합합니다. 이 함수는 확률 분포 간의 거리를 측정합니다. 여기에서는 정답인 타깃 분포와 예측 분포 사이의 거리입니다.\n",
        "\n",
        "나중에 회귀(regression)문제에 대해 살펴 볼 때 평균 제곱 오차(mean_squared error) 손실 함수를 어떻게 사용하는지 알아 보겠습니다.\n",
        "\n",
        "옵티마이저로는 Adam 알고리즘을 구현한 AdamOptimizer를 사용합니다. 경사하강법을 사용하는 GradientDescentOptimizer보다 성능이 좋다고 합니다.\n",
        "\n",
        "이제 모델이 사용할 옵티마이저와 손실 함수를 설정해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPlJCXH1brcd"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoQdjkJ3cdoR"
      },
      "source": [
        "## 5. 검증 세트 만들기\n",
        "\n",
        "모델을 훈련할 때 모델이 만난 적 없는 데이터에서 정확도를 확인하는 것이 좋습니다. 원본 훈련 데이터에서 10,000개의 샘플을 떼어내어 검증 세트를 만들겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd2qcHHEwl4G"
      },
      "source": [
        "x_val = train_data[:10000]  # 0~9999, 검증 데이터(10,000개)\n",
        "partial_x_train = train_data[10000:] # 10000~24999, 훈련 데이터(15,000개)\n",
        "\n",
        "y_val = train_labels[:10000]  # 0~9999, 검증 데이터\n",
        "partial_y_train = train_labels[10000:]  # 10000~24999, 훈련 데이터"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AteAilqmw6nP"
      },
      "source": [
        "## 6. 모델 훈련\n",
        "\n",
        "훈련 데이터셋(partial_x_train, partial_y_train)을 512개의 작은 미니배치(mini-batches)로 분할해 입력으로 사용합니다.\n",
        "\n",
        "512개씩 나누어 전체 훈련 데이터셋을 모델 학습에 사용하는 것을 40번 반복합니다.\n",
        "\n",
        "모델이 학습되는 동안 모델의 손실과 정확도를 계산하기 위해 검증 데이터셋(x_val, y_val)을 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KN69q4iKxfTC",
        "outputId": "a46d7785-4a9c-4ea6-a1e6-afbbc23e472b"
      },
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "30/30 [==============================] - 4s 18ms/step - loss: 0.6922 - accuracy: 0.5628 - val_loss: 0.6907 - val_accuracy: 0.6677\n",
            "Epoch 2/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.6875 - accuracy: 0.6745 - val_loss: 0.6838 - val_accuracy: 0.7051\n",
            "Epoch 3/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.6777 - accuracy: 0.7500 - val_loss: 0.6719 - val_accuracy: 0.6901\n",
            "Epoch 4/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.6609 - accuracy: 0.7431 - val_loss: 0.6525 - val_accuracy: 0.7567\n",
            "Epoch 5/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.6357 - accuracy: 0.7784 - val_loss: 0.6253 - val_accuracy: 0.7774\n",
            "Epoch 6/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.6022 - accuracy: 0.7988 - val_loss: 0.5917 - val_accuracy: 0.7897\n",
            "Epoch 7/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.5632 - accuracy: 0.8188 - val_loss: 0.5546 - val_accuracy: 0.7993\n",
            "Epoch 8/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.5211 - accuracy: 0.8345 - val_loss: 0.5156 - val_accuracy: 0.8202\n",
            "Epoch 9/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.4786 - accuracy: 0.8505 - val_loss: 0.4786 - val_accuracy: 0.8367\n",
            "Epoch 10/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4383 - accuracy: 0.8640 - val_loss: 0.4450 - val_accuracy: 0.8445\n",
            "Epoch 11/40\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.4022 - accuracy: 0.8739 - val_loss: 0.4148 - val_accuracy: 0.8526\n",
            "Epoch 12/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3700 - accuracy: 0.8825 - val_loss: 0.3902 - val_accuracy: 0.8594\n",
            "Epoch 13/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3422 - accuracy: 0.8873 - val_loss: 0.3697 - val_accuracy: 0.8644\n",
            "Epoch 14/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3187 - accuracy: 0.8945 - val_loss: 0.3530 - val_accuracy: 0.8681\n",
            "Epoch 15/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2981 - accuracy: 0.9009 - val_loss: 0.3398 - val_accuracy: 0.8698\n",
            "Epoch 16/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2806 - accuracy: 0.9046 - val_loss: 0.3282 - val_accuracy: 0.8745\n",
            "Epoch 17/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2645 - accuracy: 0.9100 - val_loss: 0.3192 - val_accuracy: 0.8754\n",
            "Epoch 18/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2503 - accuracy: 0.9152 - val_loss: 0.3114 - val_accuracy: 0.8786\n",
            "Epoch 19/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2379 - accuracy: 0.9187 - val_loss: 0.3054 - val_accuracy: 0.8795\n",
            "Epoch 20/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2265 - accuracy: 0.9221 - val_loss: 0.3003 - val_accuracy: 0.8808\n",
            "Epoch 21/40\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2155 - accuracy: 0.9265 - val_loss: 0.2958 - val_accuracy: 0.8825\n",
            "Epoch 22/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2061 - accuracy: 0.9297 - val_loss: 0.2926 - val_accuracy: 0.8819\n",
            "Epoch 23/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.1967 - accuracy: 0.9343 - val_loss: 0.2909 - val_accuracy: 0.8820\n",
            "Epoch 24/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.1881 - accuracy: 0.9371 - val_loss: 0.2879 - val_accuracy: 0.8836\n",
            "Epoch 25/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.1806 - accuracy: 0.9419 - val_loss: 0.2862 - val_accuracy: 0.8843\n",
            "Epoch 26/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.1726 - accuracy: 0.9440 - val_loss: 0.2850 - val_accuracy: 0.8849\n",
            "Epoch 27/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.1657 - accuracy: 0.9477 - val_loss: 0.2845 - val_accuracy: 0.8850\n",
            "Epoch 28/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.1596 - accuracy: 0.9497 - val_loss: 0.2847 - val_accuracy: 0.8849\n",
            "Epoch 29/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.1535 - accuracy: 0.9527 - val_loss: 0.2845 - val_accuracy: 0.8857\n",
            "Epoch 30/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1471 - accuracy: 0.9547 - val_loss: 0.2849 - val_accuracy: 0.8856\n",
            "Epoch 31/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1412 - accuracy: 0.9571 - val_loss: 0.2862 - val_accuracy: 0.8846\n",
            "Epoch 32/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1360 - accuracy: 0.9591 - val_loss: 0.2869 - val_accuracy: 0.8864\n",
            "Epoch 33/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1313 - accuracy: 0.9617 - val_loss: 0.2877 - val_accuracy: 0.8857\n",
            "Epoch 34/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1267 - accuracy: 0.9629 - val_loss: 0.2897 - val_accuracy: 0.8856\n",
            "Epoch 35/40\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.1216 - accuracy: 0.9649 - val_loss: 0.2914 - val_accuracy: 0.8845\n",
            "Epoch 36/40\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.1170 - accuracy: 0.9671 - val_loss: 0.2936 - val_accuracy: 0.8851\n",
            "Epoch 37/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1129 - accuracy: 0.9695 - val_loss: 0.2949 - val_accuracy: 0.8859\n",
            "Epoch 38/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1089 - accuracy: 0.9709 - val_loss: 0.2973 - val_accuracy: 0.8853\n",
            "Epoch 39/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1050 - accuracy: 0.9723 - val_loss: 0.3008 - val_accuracy: 0.8844\n",
            "Epoch 40/40\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1011 - accuracy: 0.9735 - val_loss: 0.3029 - val_accuracy: 0.8842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwRHgoHsyHmD"
      },
      "source": [
        "## 7. 모델 평가\n",
        "\n",
        "모델의 성능을 확인해봅시다. 손실과 정확도를 반환합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIvJLJq9yOme",
        "outputId": "559a83a7-90b6-4545-935e-c88ad9cee376"
      },
      "source": [
        "results = model.evaluate(test_data, test_labels, verbose=2)\n",
        "\n",
        "print(results)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 - 1s - loss: 0.3232 - accuracy: 0.8735\n",
            "[0.3232339918613434, 0.873520016670227]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqZfGKNxyWeV"
      },
      "source": [
        "이번 예제는 매우 단순한 방식을 사용하므로 **87%의 정확도**를 달성했습니다. 좀 더 심층적인 방법을 사용하면 모델은 95%에 가까운 정확도를 얻습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qbAiU_byf6H"
      },
      "source": [
        "## 8. 정확도와 손실 그래프 그리기\n",
        "\n",
        "`model.fit()`은 `History` 객체를 반환합니다. `History`에는 훈련하는 동안 일어난 모든 정보가 담긴 딕셔너리가 들어있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UDZn6kay5jB",
        "outputId": "3b2260ea-6bda-49ba-a9d1-f4ad6073025b"
      },
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PokFUK5LzCvo"
      },
      "source": [
        "네 개의 항목이 있습니다. 훈련과 검증 단계에서 모니터링하는 지표들입니다.\n",
        "\n",
        "훈련 손실과 검증 손실을 그래프로 그려 보고, 훈련 정확도와 검증 정확도 역시 그래프로 그려서 비교해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "mtU-vvnHzLR9",
        "outputId": "0881c035-579a-4e1b-935f-1b0ba53eb96a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# 'bo'는 파란색 점입니다.\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# 'b'는 파란 실선입니다.\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()  # 범례를 나타낸다.\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "ATE1cSjR0HII",
        "outputId": "98fd84c4-2f5a-4eb0-ebb5-48c1021a8246"
      },
      "source": [
        "plt.clf()  # 그림 초기화\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()  # 범례를 나타낸다.\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSGyREjb0k9D"
      },
      "source": [
        "훈련 손실은 에포크마다 감소하고, 훈련 정확도는 증가합니다. 경사 하강법 최적화를 사용할 때 볼 수 있는 현상입니다. 매 반복마다 최적화 대상의 값을 최소화합니다.\n",
        "\n",
        "하지만 검증 손실과 검증 정확도에서는 약 20번째 에포크 이후에는 변화가 없습니다. 이렇듯 훈련 데이터셋을 입력으로 사용했을 때보다 검증 데이터셋을 입력으로 사용했을 때 결과가 좋지 못한 것을 오버피팅(overfitting)이라고 합니다.\n",
        "\n",
        "훈련용 데이터셋에 최적화되어 있어서 새로운 데이터셋을 입력으로 사용시 모델의 성능이 떨어지는 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myqQW6cX2TjH"
      },
      "source": [
        "## 9. 예측하기\n",
        "\n",
        "학습된 모델에 테스트 데이터셋을 입력으로 사용하여 예측해봅시다.\n",
        "\n",
        "예측된 값 중 10개만 출력해보았습니다. 첫 번째 줄은 신경망의 출력이고, 두 번째 줄은 어느 클래스에 속하는지 판정한 결과입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXNTddVJ2Ye5",
        "outputId": "e2888570-26b5-4994-fbcb-53befc4db270"
      },
      "source": [
        "predictions = model.predict(test_data)\n",
        "print(predictions[0:10].T)\n",
        "\n",
        "predict_class=model.predict_classes(test_data)\n",
        "print(predict_class[0:10].T)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.07413818 0.99991167 0.8404214  0.7174338  0.99543285 0.93125075\n",
            "  0.97053033 0.01920953 0.9759099  0.9998504 ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[0 1 1 1 1 1 1 0 1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}